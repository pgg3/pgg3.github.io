---
permalink: /
title: "Zeyu Qin (秦泽钰)"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<span class='anchor' id='about-me'></span>


# 🎓 About Me

I am Zeyu Qin (秦泽钰), a Ph.D. student of [Computer Science & Engineering](https://cse.hkust.edu.hk/) at [Hong Kong University of Science and Technology](https://hkust.edu.hk/) (HKUST). My advisors are [Prof. Minhao Cheng](https://cmhcbb.github.io/) and [Prof. Nevin L. Zhang](https://www.cse.ust.hk/faculty/lzhang/). My research interest is broadly on _AI Safety, Interpretability, and Alignment_. **Currently, my focus is on enhancing the safety and interpretability of Large Pretrained Models, specifically for Eliciting Latent Knowledge (ELK).**

_I am very fortunate to have worked with lots of distinguished researchers: Prof. Baoyuan Wu, Dr. Yanbo Fan, Dr. Li Shen, Prof. Hongyuan Zha, Dr. Jiancong Xiao, and Prof. Piji Li. I had an amazing four years at LGU with my good friends from Room 310 and Room 224. Miss you, guys!_


# 📜 News
- *2023.10*: I will go to New Orleans to attend NeurIPS 2023.
- *2023.09*: **Two papers (one spotlight) have been accepted by NeurIPS 2023**: 1. Feature shift tuning which achieves SOTA purification performance against backdoor attacks; 2. Spotlight! Imitation learning from imperfect demonstrations (See [Ziniu Li](http://www.liziniu.org/)).
- *2023.05*: New work has been accepted by KDD 2023: The first study about **robustness from personalization in FL against backdoor attacks**.
- *2022.10*: I will go to New Orleans to attend NeurIPS 2022.
- *2022.09*: The paper about **adversarial transferability (Reverse Adversarial Perturbation)** was accepted by NeurIPS 2022.
- *2021.09*: The paper about defense against query-based attacks **(Random Noise Defense)** was accepted by NeurIPS 2021.

# 📝 Publications 

\* denoting equal contribution

- **Towards Stable Backdoor Purification through Feature Shift Tuning**    
Rui Min\*, **Zeyu Qin**\*, Li Shen, Minhao Cheng.    
*In Advances in Neural Information Processing Systems (**NeurIPS**), 2023.* [[arxiv](https://arxiv.org/abs/2310.01875)] [[OpenReview](https://openreview.net/forum?id=8muKbaAgsh)] [[code](https://github.com/AISafety-HKUST/stable_backdoor_purification)]

- **Imitation Learning from Imperfection: Theoretical Justifications and Algorithms (Spotlight!)**    
Ziniu Li\*, Tian Xu\*, **Zeyu Qin**, Yang Yu, Zhiquan Luo.    
*In Advances in Neural Information Processing Systems (**NeurIPS**), 2023.* [[OpenReview](https://openreview.net/forum?id=vO04AzsB49)]  
(This is excellent work from Ziniu and Tian. I only conducted part of the experiments. I almost have no idea about Imitation Learning 😂.)

- **Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks**   
**Zeyu Qin**, Liuyi Yao, Daoyuan Chen, Yaliang Li, Boling Ding, Minhao Cheng.   
*The 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (**KDD**), 2023.* [[arxiv](https://arxiv.org/abs/2302.01677)] [[code](https://github.com/alibaba/FederatedScope/tree/backdoor-bench)]


- **Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators**  
Liang Chen, Yang Deng, Yatao Bian, **Zeyu Qin**, Bingzhe Wu, Tat-Seng Chua, Kam-Fai Wong.   
*The 2023 Conference on Empirical Methods in Natural Language Processing (**EMNLP**), 2023.* [[arxiv](https://arxiv.org/abs/2310.07289)]

- **Adaptive Smoothness-weighted Adversarial Training for Multiple Perturbations with Its Stability Analysis.**  
Jiancong Xiao, **Zeyu Qin**, Yanbo Fan, Baoyuan Wu, Jue Wang, Zhi-Quan Luo.    
*ICML 2023 Workshop AdvML-Frontiers, 2023* [[arxiv](https://arxiv.org/abs/2210.00557)]

- **Boosting the Transferability of Adversarial Attacks with Reverse Adversarial Perturbation**    
**Zeyu Qin**\*, Yanbo Fan\*, Yi Liu, Li Shen, Yong Zhang, Jue Wang, Baoyuan Wu.    
*In Advances in Neural Information Processing Systems (**NeurIPS**), 2022.* [[arxiv](https://arxiv.org/abs/2210.05968)] [[OpenReview](https://openreview.net/forum?id=k5uFiFLWv3X)] [[code](https://github.com/Alan-Qin/Transfer_attack_RAP)]

- **Random Noise Defense Against Query-Based Black-Box Attacks**    
**Zeyu Qin**, Yanbo Fan, Hongyuan Zha, Baoyuan Wu.    
*In Advances in Neural Information Processing Systems (**NeurIPS**), 2021.* [[arxiv](https://arxiv.org/abs/2104.11470)] [[OpenReview](https://openreview.net/forum?id=ZPSD4xZc6j8)] [[code](https://github.com/SCLBD/BlackboxBench)]


# 📝 Preprints
\* denoting equal contribution

- **Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping**     
Haoyu Wang, Guozheng Ma, Ziqiao Meng, **Zeyu Qin**, Li Shen, Zhong Zhang, Bingzhe Wu, Liu Liu, Yatao Bian, Tingyang Xu, Xueqian Wang, Peilin Zhao.    
*Arxiv, 2024.* [[arxiv](https://arxiv.org/abs/2402.07610)]



# 🎖 Honors and Awards
- *2022.10*, NeurIPS 2022 Scholar Award
- *2021.04*, Poster Runner-Up Reward of The First Doctoral and Postdoctoral Academic Forum of Shenzhen Research Institute of Big Data

  
# 📖 Educations
- *2022.08 - Now*, Ph.D. student in Computer Science & Engineering, The Hong Kong University of Science and Technology.
- *2018.08 - 2022.05 (Ph.D. --> M.Phil)*, M.Phil in Computer and Information Engineering, The Chinese University of Hong Kong, Shenzhen.
- *2014.09 - 2018.06*, B.Eng. in Information Engineering, Nanjing University of Aeronautics and Astronautics.

# 💬 Invited Talks
- *2022.10*, Adversarial Transferability in AI Times Forum.

# 💻 Internships
- Summer 2022: Research Intern, Alibaba Damo Academy, Hangzhou, China
- July 2021 -- May 2022: Research Intern, Tencent AI Lab, Shenzhen, China
- January 2020 -- October 2020: Research Intern, Tencent AI Lab, Shenzhen, China
